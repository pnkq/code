
Model A:
  [stack :+ queue.head] ==> LSTM word ==> Dense(softmax) ==> best transition

Model B: 
  [stack :+ queue.head] ==> LSTM  word ==\
                                      Merge(concat) ==> Dense(softmax) ==> best transition
      [bag of features] ==> Dense      ==/

Model C: 
  [stack :+ queue.head] ==> LSTM word  ==\
  [stack :+ queue.head] ==> LSTM upos  === Merge(concat) ==> Dense(softmax) ==> best transition                                      
      [bag of features] ==> Dense      ==/


Model D: 
  [stack :+ queue.head] ==> LSTM word  ==\
  [stack :+ queue.head] ==> LSTM upos  === Merge(concat) ==> Dense(softmax) ==> best transition                                      
      [bag of features] ==> Dense      ==/
    [BERT vec. of trs.] ==> Dense      ==/


// bloop run -p con -m vlp.dep.TransitionClassifier -- -v -m train -c mlp -J-Xmx8g

// stack length of the parsing context (AS) on the dev. split of EWT.
// ---+-----+
// |  s|count|
// +---+-----+
// |  2|11985|
// |  3|10022|
// |  1| 8397|
// |  4| 7614|
// |  5| 4772|
// |  6| 2623|
// |  0| 1860|
// |  7| 1378|
// |  8|  690|
// |  9|  323|
// | 10|  145|
// | 11|   58|
// | 12|   18|
// | 13|    6|
// | 14|    2|
// | 15|    2|
// | 16|    2|
// | 17|    1|
// +---+-----+

// There are 49,898 samples.

// On the train split of the EWT.
// +---+-----+
// |  s|count|
// +---+-----+
// |  2|87476|
// |  3|80081|
// |  4|66079|
// |  1|57164|
// |  5|45949|
// |  6|27676|
// |  7|15053|
// |  0|11666|
// |  8| 7696|
// |  9| 3762|
// | 10| 1793|
// | 11|  857|
// | 12|  435|
// | 13|  253|
// | 14|  160|
// | 15|   84|
// | 16|   41|
// | 17|   18|
// | 18|    7|
// | 19|    2|
// +---+-----+

// There are 406,252 samples. 